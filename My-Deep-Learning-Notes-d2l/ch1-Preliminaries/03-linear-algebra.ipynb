{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([1.]), tensor([1.5000]), tensor([6.]), tensor([9.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.tensor([3.0])\n",
    "y=torch.tensor([2.0])\n",
    "x+y,x-y,x/y,x*y,x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=torch.arange(20).reshape(5,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=torch.tensor([[1,2,3,],[2,0,4],[3,4,5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.T#B的转置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "         [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "         [24, 25, 26, 27, 28, 29, 30, 31]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.arange(64).reshape(2,4,8)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [24, 25, 26, 27],\n",
       "         [28, 29, 30, 31]],\n",
       "\n",
       "        [[32, 33, 34, 35],\n",
       "         [36, 37, 38, 39],\n",
       "         [40, 41, 42, 43],\n",
       "         [44, 45, 46, 47],\n",
       "         [48, 49, 50, 51],\n",
       "         [52, 53, 54, 55],\n",
       "         [56, 57, 58, 59],\n",
       "         [60, 61, 62, 63]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.arange(64).reshape(2,8,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [10, 11],\n",
       "         [12, 13],\n",
       "         [14, 15]],\n",
       "\n",
       "        [[16, 17],\n",
       "         [18, 19],\n",
       "         [20, 21],\n",
       "         [22, 23]],\n",
       "\n",
       "        [[24, 25],\n",
       "         [26, 27],\n",
       "         [28, 29],\n",
       "         [30, 31]],\n",
       "\n",
       "        [[32, 33],\n",
       "         [34, 35],\n",
       "         [36, 37],\n",
       "         [38, 39]],\n",
       "\n",
       "        [[40, 41],\n",
       "         [42, 43],\n",
       "         [44, 45],\n",
       "         [46, 47]],\n",
       "\n",
       "        [[48, 49],\n",
       "         [50, 51],\n",
       "         [52, 53],\n",
       "         [54, 55]],\n",
       "\n",
       "        [[56, 57],\n",
       "         [58, 59],\n",
       "         [60, 61],\n",
       "         [62, 63]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.arange(64).reshape(8,4,2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "B=A.clone()# 分配新内存，把A的一个副本给B\n",
    "A,A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hadamard Product\n",
    "A*B#按元素乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9],\n",
       "         [10, 11, 12, 13]],\n",
       "\n",
       "        [[14, 15, 16, 17],\n",
       "         [18, 19, 20, 21],\n",
       "         [22, 23, 24, 25]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=2\n",
    "X=torch.arange(24).reshape(2,3,4)\n",
    "X+a#每个元素都加a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor(6))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12, 14, 16, 18],\n",
       "         [20, 22, 24, 26],\n",
       "         [28, 30, 32, 34]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,X.shape\n",
    "X_sum_axis0=X.sum(axis=0)\n",
    "X_sum_axis0,X_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12, 15, 18, 21],\n",
       "         [48, 51, 54, 57]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sum_axis1=X.sum(axis=1)\n",
    "X_sum_axis1,X_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(11.5000), tensor(11.5000))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4).float()\n",
    "\n",
    "X.mean(),X.sum()/X.numel()# numel: number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A=A.sum(axis=1,keepdims=True)# keep dimension\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A/sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.],\n",
       "        [24., 28., 32., 36.],\n",
       "        [40., 45., 50., 55.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)  # 计算矩阵或张量 A 在指定轴上的累加和（cumulative sum）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  3.,  6.],\n",
       "        [ 4.,  9., 15., 22.],\n",
       "        [ 8., 17., 27., 38.],\n",
       "        [12., 25., 39., 54.],\n",
       "        [16., 33., 51., 70.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.ones(4,dtype=torch.float32)\n",
    "x=torch.arange(4,dtype=torch.float32)\n",
    "x,y,torch.dot(x,y)#dot  点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape,x.shape,torch.mv(A,x)# 矩阵-向量乘法（matrix-vector multiplication）\n",
    "# 这是 PyTorch 提供的专门用于矩阵乘以向量的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0529, 0.5859, 0.8192],\n",
       "        [0.0798, 0.3788, 0.9013],\n",
       "        [0.3049, 0.6713, 0.6352],\n",
       "        [0.0947, 0.9873, 0.0092]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=torch.rand(4,3,dtype=torch.float32)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9738,  4.6832,  2.1993],\n",
       "        [ 3.1033, 15.1762, 11.6589],\n",
       "        [ 5.2329, 25.6693, 21.1184],\n",
       "        [ 7.3624, 36.1623, 30.5780],\n",
       "        [ 9.4920, 46.6553, 40.0375]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(A,B)# （matrix-MATRIX multiplication）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#范数；向量或矩阵的长度\n",
    "# L2范数是向量元素平方和的平方根\n",
    "u=torch.tensor([3.0,-4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#L1范数：向量元素的绝对值之和\n",
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frobunius norm :矩阵元素平方和的平方根\n",
    "#把矩阵拉成一个向量，求向量的范数\n",
    "torch.norm(torch.ones((4,9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按特定轴求和\n",
    "shape:[5,4]\n",
    "axis:  0,1\n",
    "axis=1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]],\n",
       "\n",
       "        [[15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23],\n",
       "         [24, 25, 26],\n",
       "         [27, 28, 29]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP=torch.arange(30).reshape(2,5,3)\n",
    "PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10, 11],\n",
       "         [12, 13, 14, 15, 16, 17],\n",
       "         [18, 19, 20, 21, 22, 23]],\n",
       "\n",
       "        [[24, 25, 26, 27, 28, 29],\n",
       "         [30, 31, 32, 33, 34, 35],\n",
       "         [36, 37, 38, 39, 40, 41],\n",
       "         [42, 43, 44, 45, 46, 47]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP=torch.arange(48).reshape(2,4,6)\n",
    "PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP.sum().shape#标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 26, 28, 30, 32, 34],\n",
       "        [36, 38, 40, 42, 44, 46],\n",
       "        [48, 50, 52, 54, 56, 58],\n",
       "        [60, 62, 64, 66, 68, 70]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 36,  40,  44,  48,  52,  56],\n",
       "        [132, 136, 140, 144, 148, 152]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 6])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP.sum(axis=1,keepdims=True).shape#keepdims:仍然还是三维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.范数\n",
      "向量的𝐿2范数: tensor(5.)\n",
      "向量的𝐿1范数: tensor(7.)\n",
      "v: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "矩阵的𝐿2范数: tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "print('9.范数')\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "print('向量的𝐿2范数:', torch.norm(u))  # 向量的𝐿2范数\n",
    "print('向量的𝐿1范数:', torch.abs(u).sum())  # 向量的𝐿1范数\n",
    "v = torch.ones((4, 9))\n",
    "print('v:', v)\n",
    "print('矩阵的𝐿2范数:', torch.norm(v))  # 矩阵的𝐿2范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.理解pytorch中的gather()函数\n",
      "11.1二维矩阵上gather()函数\n",
      "a: tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]])\n",
      "b: tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0]])\n",
      "cc: tensor([[5, 1, 2, 3, 4],\n",
      "        [0, 1, 7, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n",
      "dd: tensor([[ 1,  0,  0,  0,  0],\n",
      "        [ 5,  5,  6,  5,  5],\n",
      "        [10, 10, 10, 10, 10]])\n"
     ]
    }
   ],
   "source": [
    "print('11.理解pytorch中的gather()函数')\n",
    "a = torch.arange(15).view(3, 5)# 生成一个包含从 0 到 14 的张量，并将其重塑为形状为 (3, 5) 的二维张量。\n",
    "print('11.1二维矩阵上gather()函数')\n",
    "print('a:', a)\n",
    "b = torch.zeros_like(a)# 创建一个与张量 a 形状相同的全零张量。\n",
    "b[1][2] = 1  ##给指定索引的元素赋值\n",
    "b[0][0] = 1  ##给指定索引的元素赋值\n",
    "print('b:', b)\n",
    "cc = a.gather(0, b)  # dim=0'\n",
    "print('cc:', cc)\n",
    "dd = a.gather(1, b)  # dim=1\n",
    "print('dd:', dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2三维矩阵上gather()函数\n",
      "a: tensor([[[22,  1,  4,  8, 29],\n",
      "         [29, 16,  8,  7, 11],\n",
      "         [ 4, 23, 17,  7, 23]],\n",
      "\n",
      "        [[17,  0, 27, 11, 19],\n",
      "         [27, 14, 29,  7,  0],\n",
      "         [ 5, 24, 18,  0, 19]]])\n",
      "True\n",
      "b: tensor([[[22, 16, 17,  8, 23],\n",
      "         [22,  1,  4,  8, 29],\n",
      "         [29, 16,  8,  7, 11]],\n",
      "\n",
      "        [[27, 24, 18,  0, 19],\n",
      "         [17,  0, 27, 11, 19],\n",
      "         [ 5, 24, 18,  0, 19]]])\n",
      "c: tensor([[[22,  1,  4, 22,  4],\n",
      "         [29, 29, 29, 29, 29],\n",
      "         [23, 23, 23, 23, 23]],\n",
      "\n",
      "        [[ 0, 27, 27, 27, 27],\n",
      "         [27, 27, 27, 27, 27],\n",
      "         [18, 18, 18, 18, 18]]])\n",
      "d: tensor([[[22,  0, 27,  8, 19],\n",
      "         [29, 14, 29,  7,  0],\n",
      "         [ 5, 24, 18,  0, 19]],\n",
      "\n",
      "        [[17,  1,  4,  8, 29],\n",
      "         [29, 16,  8,  7, 11],\n",
      "         [ 5, 24, 17,  7, 23]]])\n"
     ]
    }
   ],
   "source": [
    "print('11.2三维矩阵上gather()函数')\n",
    "a = torch.randint(0, 30, (2, 3, 5))\n",
    "print('a:', a)\n",
    "index = torch.LongTensor([[[0, 1, 2, 0, 2],\n",
    "                           [0, 0, 0, 0, 0],\n",
    "                           [1, 1, 1, 1, 1]],\n",
    "                          [[1, 2, 2, 2, 2],\n",
    "                           [0, 0, 0, 0, 0],\n",
    "                           [2, 2, 2, 2, 2]]])\n",
    "print(a.size() == index.size())\n",
    "b = torch.gather(a, 1, index)\n",
    "print('b:', b)\n",
    "c = torch.gather(a, 2, index)\n",
    "print('c:', c)\n",
    "index2 = torch.LongTensor([[[0, 1, 1, 0, 1],\n",
    "                            [0, 1, 1, 1, 1],\n",
    "                            [1, 1, 1, 1, 1]],\n",
    "                           [[1, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0],\n",
    "                            [1, 1, 0, 0, 0]]])\n",
    "d = torch.gather(a, 0, index2)\n",
    "print('d:', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.理解pytorch中的max()和argmax()函数\n",
      "a: tensor([[1, 2, 3],\n",
      "        [3, 2, 1]])\n",
      "a.argmax(1): tensor([2, 0])\n",
      "a.max(1): torch.return_types.max(\n",
      "values=tensor([3, 3]),\n",
      "indices=tensor([2, 0]))\n",
      "a.max(1)[1]: tensor([2, 0])\n"
     ]
    }
   ],
   "source": [
    "print('12.理解pytorch中的max()和argmax()函数')\n",
    "a = torch.tensor([[1, 2, 3], [3, 2, 1]])\n",
    "b = a.argmax(1)\n",
    "c = a.max(1)\n",
    "d = a.max(1)[1]\n",
    "print('a:', a)\n",
    "print('a.argmax(1):', b)\n",
    "print('a.max(1):', c)\n",
    "print('a.max(1)[1]:', d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4]), tensor([0, 1, 2, 3, 4]), tensor(30))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "xx=torch.arange(5)\n",
    "yy=torch.arange(5)\n",
    "xx,yy,torch.dot(xx,yy)\n",
    "\n",
    "# xxx=torch.arange(12).reshape(3,4)\n",
    "# yyy=torch.arange(12).reshape(3,4)\n",
    "# xxx,yyy,torch.dot(xxx,yyy)\n",
    "\n",
    "#########torch.dot是计算两个一维张量间的点积\n",
    "##就相当于权重和得分的相乘相加\n",
    "##点积是相同位置按元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]]),\n",
       " tensor([0, 1, 2, 3, 4]),\n",
       " tensor([ 30,  80, 130]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵向量积\n",
    "A=torch.arange(15).reshape(3,5)\n",
    "x=torch.arange(5)\n",
    "A,x,torch.mv(A,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('13.item()函数')\n",
    "a = torch.Tensor([1, 2, 3])\n",
    "print('a[0]:', a[0])  # 直接取索引返回的是tensor数据\n",
    "print('a[0].item():', a[0].item())  # 获取python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#标量\n",
    "\n",
    "import torch\n",
    "x=torch.tensor(3.0)\n",
    "y=torch.tensor(2.0)\n",
    "x+y,x*y,x/y,x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#向量\n",
    "x=torch.arange(7)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵\n",
    "A=torch.arange(12).reshape(3,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8],\n",
       "        [ 1,  5,  9],\n",
       "        [ 2,  6, 10],\n",
       "        [ 3,  7, 11]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B==B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/remote-home/chenkaijie/DeepLearning/My-DL-Learning/ch1/03-linear-algebra.ipynb 单元格 57\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22456e762d33303630227d/remote-home/chenkaijie/DeepLearning/My-DL-Learning/ch1/03-linear-algebra.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m A\u001b[39m==\u001b[39mA\u001b[39m.\u001b[39mT\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "A==A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=torch.arange(24).reshape(2,3,4)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(C)# len(C) 返回张量的第一个维度的大小，因为 len 函数在 PyTorch 中实际上返回的是张量的第一个维度的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12, 14, 16, 18],\n",
       "         [20, 22, 24, 26],\n",
       "         [28, 30, 32, 34]]),\n",
       " tensor([[12, 15, 18, 21],\n",
       "         [48, 51, 54, 57]]),\n",
       " tensor([[ 6, 22, 38],\n",
       "         [54, 70, 86]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.sum(axis=0),C.sum(axis=1),C.sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
